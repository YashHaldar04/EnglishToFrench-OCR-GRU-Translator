{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text extracted and saved in extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# If Tesseract isn't in PATH, specify it:\n",
    "# pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "\n",
    "img = Image.open(\"scanned_page_bw.png\")\n",
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"âœ… Text extracted and saved in extracted_text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Raw OCR Output:\n",
      "BILSTM-GCN Based Stuttering Detection with Corrective\n",
      "Feedback Leveraging SEP-28k.doc\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "âœ¨ Corrected Text:\n",
      "BILSTM-GCN Based Stuttering Detection with Corrective Feedback Averaging SEP-Ask.do\n",
      "\n",
      "âœ… Raw text saved in extracted_text_raw.txt\n",
      "âœ… Corrected text saved in extracted_text_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "\n",
    "# If Tesseract isn't in PATH, specify it:\n",
    "# pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "\n",
    "def fix_ocr_errors(text):\n",
    "    \"\"\"\n",
    "    Fix common OCR errors using NLP techniques:\n",
    "    1. Replace common OCR character mistakes (0 -> O, 1 -> I, etc.)\n",
    "    2. Fix spelling errors\n",
    "    3. Correct grammar\n",
    "    4. Normalize capitalization\n",
    "    \"\"\"\n",
    "    # Step 1: Fix common OCR character substitutions\n",
    "    ocr_corrections = {\n",
    "        r'\\b0': 'O',  # 0 at word start -> O\n",
    "        r'0\\b': 'o',  # 0 at word end -> o\n",
    "        r'1': 'l',    # 1 -> l (in some contexts)\n",
    "        r'5': 'S',    # 5 -> S\n",
    "        r'8': 'B',    # 8 -> B\n",
    "    }\n",
    "    \n",
    "    corrected_text = text\n",
    "    for pattern, replacement in ocr_corrections.items():\n",
    "        corrected_text = re.sub(pattern, replacement, corrected_text)\n",
    "    \n",
    "    # Step 2: Spell checking and correction\n",
    "    spell = SpellChecker()\n",
    "    words = corrected_text.split()\n",
    "    corrected_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Keep punctuation\n",
    "        if word and word[-1] in '.,!?;:':\n",
    "            punct = word[-1]\n",
    "            clean_word = word[:-1]\n",
    "            corrected = spell.correction(clean_word)\n",
    "            if corrected:\n",
    "                corrected_words.append(corrected + punct)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "        else:\n",
    "            corrected = spell.correction(word)\n",
    "            if corrected:\n",
    "                corrected_words.append(corrected)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "    \n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    \n",
    "    # Step 3: Grammar correction using TextBlob\n",
    "    blob = TextBlob(corrected_text)\n",
    "    corrected_text = str(blob.correct())\n",
    "    \n",
    "    # Step 4: Normalize capitalization (capitalize first letter of sentences)\n",
    "    sentences = re.split(r'([.!?]\\s+)', corrected_text)\n",
    "    normalized_sentences = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i % 2 == 0 and sentence:  # Actual sentence, not delimiter\n",
    "            normalized_sentences.append(sentence[0].upper() + sentence[1:])\n",
    "        else:\n",
    "            normalized_sentences.append(sentence)\n",
    "    \n",
    "    corrected_text = ''.join(normalized_sentences)\n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "# Read image and extract text\n",
    "img = Image.open(\"scanned_page_bw.png\")\n",
    "raw_text = pytesseract.image_to_string(img)\n",
    "\n",
    "print(\"ðŸ“„ Raw OCR Output:\")\n",
    "print(raw_text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Apply NLP corrections\n",
    "corrected_text = fix_ocr_errors(raw_text)\n",
    "\n",
    "print(\"âœ¨ Corrected Text:\")\n",
    "print(corrected_text)\n",
    "\n",
    "# Save both versions\n",
    "with open(\"extracted_text_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(raw_text)\n",
    "\n",
    "with open(\"extracted_text_corrected.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(corrected_text)\n",
    "\n",
    "print(\"\\nâœ… Raw text saved in extracted_text_raw.txt\")\n",
    "print(\"âœ… Corrected text saved in extracted_text_corrected.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
